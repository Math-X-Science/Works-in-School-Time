{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8b67a3-2c45-43fd-bebc-ae0a77a1dde9",
   "metadata": {},
   "source": [
    "## 合并数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848de59e-69f9-4c52-a16a-72071cbae479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv():\n",
    "    path = 'cleaned/'\n",
    "    files = os.listdir(path)\n",
    "    files_csv = [f for f in files if f.endswith('.csv')]\n",
    "    df = pd.DataFrame()\n",
    "    for file in files_csv:\n",
    "        df = pd.concat([df, pd.read_csv(path + file)], axis=0)\n",
    "    df.to_csv('novel.csv',  sep='|', index=False)\n",
    "\n",
    "merge_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f118dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "#df = pd.read_csv('small.csv', sep=',')\n",
    "df.to_csv('small.csv', sep='|',index=False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a7590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已保存为 'formatted_novel.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设您的CSV文件名为 'translations.csv' 且位于当前目录中\n",
    "file_name = 'novel.csv'\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv(file_name, names=['en', 'cn'])  # 我们指定列名，因为CSV没有头\n",
    "\n",
    "# 创建一个新的列，包含翻译的字典\n",
    "df['translation'] = df.apply(lambda row: {'en': row['en'], 'cn': row['cn']}, axis=1)\n",
    "\n",
    "# 选择需要写入的列\n",
    "output_df = df[['translation']]\n",
    "\n",
    "# 写入到新的CSV文件中\n",
    "output_df.to_csv('formatted_novel.csv', index=True, index_label='**translation**', header=True, encoding='utf-8')\n",
    "\n",
    "print(\"文件已保存为 'formatted_novel.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6d717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 示例数据框\n",
    "df = pd.DataFrame({\n",
    "    'en': [\"Hello, world!\", \"I love to travel around the world.\", \"Today is a beautiful day.\", \"Can you help me with my homework?\", \"The river flows gently through the valley.\"],\n",
    "    'cn': [\"你好，世界！\", \"我喜欢环游世界。\", \"今天是个美丽的一天。\", \"你能帮我做家庭作业吗？\", \"河水轻轻地流过山谷。\"]\n",
    "})\n",
    "\n",
    "# 使用管道符 | 作为分隔符写入 CSV 文件\n",
    "df.to_csv('./eval.csv', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99067ab-239c-4305-b539-a87cf97ec102",
   "metadata": {},
   "source": [
    "## 模型和简单的训练一下"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c4d45-a86a-4cf3-9eb8-616474b485e3",
   "metadata": {},
   "source": [
    "## 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634692e-b936-4073-b8e9-9e2f44c93a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "file_list = [\"novel.csv\"]\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # 处理中文\n",
    "    cn_text = ' '.join(df['cn'].astype(str))\n",
    "    cn_words = jieba.cut(cn_text)\n",
    "    cn_unique_words = list(set(cn_words))\n",
    "    \n",
    "    # 将中文唯一词汇保存到文件\n",
    "    with open('word_dict/' + file.replace('.csv', '_cn_dict.txt'), 'w', encoding='utf-8') as f:\n",
    "        for word in cn_unique_words:\n",
    "            f.write(word + '\\n')\n",
    "    \n",
    "    # 处理英文\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nlp.max_length = 1000000000\n",
    "    en_text = ' '.join(df['en'].astype(str))\n",
    "    doc = nlp(en_text)\n",
    "    \n",
    "    en_unique_words = set()\n",
    "    with tqdm(total=len(doc), desc=\"Tokenizing\") as pbar:\n",
    "        for token in doc:\n",
    "            if not token.is_stop and token.is_alpha:\n",
    "                en_unique_words.add(token.text.lower())\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # 将英文唯一词汇保存到文件\n",
    "    with open('word_dict/' + file.replace('.csv', '_en_dict.txt'), 'w', encoding='utf-8') as f:\n",
    "        for word in en_unique_words:\n",
    "            f.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a248d7-98f7-4d23-b0fb-a31a1f453617",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88242605-87e0-407e-9de2-9fb179481943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xnne/miniconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "# 定义一个包装函数来使用jieba\n",
    "def jieba_tokenizer(text):\n",
    "    return list(jieba.cut(text))\n",
    "\n",
    "# 现在使用这个函数来创建分词器\n",
    "token_transform = {}\n",
    "token_transform['en'] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "token_transform['cn'] = jieba_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "315222a9-4f59-4129-aca9-484a847a44d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Flory’s house was at the top of the maidan', ' close to the edge of the jungle. From the gate the maidan sloped sharply down', ' scorched and khaki-coloured', ' with half a dozen dazzling white bungalows scattered round it. All quaked', ' shivered in the hot air. There was an English cemetery within a white wall half-way down the hill', ' and near by a tiny tin-roofed church. Beyond that was the European Club', ' and when one looked at the Club — a dumpy one-storey wooden building — one looked at the real centre of the town. In any town in India the European Club is the spiritual citadel', ' the real seat of the British power', ' the Nirvana for which native officials and millionaires pine in vain. It was doubly so in this case', ' for it was the proud boast of Kyauktada Club that', ' almost alone of Clubs in Burma', ' it had never admitted an Oriental to membership. Beyond the Club', ' the Irrawaddy flowed huge and ochreous glittering like diamonds in the patches that caught the sun; and beyond the river stretched great wastes of paddy fields', ' ending at the horizon in a range of blackish hills.\"', '弗洛里的家在麦丹的顶端，靠近丛林的边缘。从大门开始，麦丹就急剧向下倾斜，一片焦土，呈卡其色，周围散落着半打耀眼的白色平房。所有平房都在热空气中颤抖着。半山腰的白色围墙内有一个英国墓地，附近还有一个小小的铁皮屋顶教堂。过了教堂就是欧洲俱乐部，看着俱乐部--一栋一层楼高的破旧木楼--就能看到小镇真正的中心。在印度的任何一个城镇，欧洲俱乐部都是精神堡垒，是英国势力的真正所在地，是本地官员和百万富翁孜孜以求的涅槃之地。皎塔达俱乐部引以为豪的是，在缅甸几乎所有的俱乐部中，它从未接纳过一个东方人入会。俱乐部外，伊洛瓦底江滔滔流淌，赭色的河水在阳光的照射下闪烁着钻石般的光芒；河的另一边是大片大片的稻田，地平线的尽头是一片黑色的丘陵。']\n",
      "['\"Flory had turned very pale. When he turned pale the birthmark made him hideously ugly. A pang like a blade of ice had gone through his entrails. Ma Hla May had appeared in the doorway of the bedroom. She stood with her face downcast', ' looking at him from beneath lowered brows.\"', '弗洛里的脸色变得非常苍白。当他脸色苍白时，胎记让他变得丑陋无比。他的内脏像被冰刀割过一样疼痛。马-赫拉-梅出现在卧室门口。她面无表情地站着，低垂着眉毛看着他。']\n",
      "['\"The Europeans stayed in the Club till midnight', ' and the butler popped into the room as many as half a dozen times', ' to relate a new anecdote. So far from snubbing him', ' the Europeans even encouraged him to talk. There is nothing like an earthquake for drawing people together. One more tremor', ' or perhaps two', ' and they would have asked the butler to sit down at table with them.\"', '欧洲人在俱乐部一直待到午夜，管家突然闯进房间，讲述新的趣闻轶事多达六七次。欧洲人不但没有冷落他，甚至还鼓励他说话。没有什么比地震更能把人们吸引到一起了。如果再有一次或两次地震，他们就会请管家和他们一起坐下来。']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_index = [155,963,1167]\n",
    "for random_data in random_index:\n",
    "    print(data[random_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c25874-dce4-4027-9dba-45384c3f4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_two_elements(row):\n",
    "    \"\"\"\n",
    "    Ensure each row has exactly two elements, source and target.\n",
    "    \n",
    "    Args:\n",
    "    - row: A list containing source and target sentences.\n",
    "    \n",
    "    Returns:\n",
    "    - A tuple with the first two elements if the row has at least two elements, \n",
    "      otherwise None.\n",
    "    \"\"\"\n",
    "    if len(row) >= 2:\n",
    "        return (row[0], row[1])  # Take first two elements\n",
    "    else:\n",
    "        return None  # Or handle missing data as needed\n",
    "\n",
    "\n",
    "# Filter data to keep only rows with two or more elements\n",
    "filtered_data = [ensure_two_elements(row) for row in data if ensure_two_elements(row) is not None]\n",
    "\n",
    "# Define text_to_indices function\n",
    "def text_to_indices(text, lang, vocab):\n",
    "    \"\"\"\n",
    "    Convert text to indices using the provided vocabulary.\n",
    "    \n",
    "    Args:\n",
    "    - text: The input text to be converted.\n",
    "    - lang: The language of the text ('en' or 'cn').\n",
    "    - vocab: The vocabulary object for the language.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of indices representing the text.\n",
    "    \"\"\"\n",
    "    indices = [vocab[token] if token in vocab else vocab['<unk>'] for token in token_transform[lang](text)]\n",
    "    return indices\n",
    "\n",
    "# Convert texts to indices\n",
    "indexed_data = [(text_to_indices(src, 'en', vocab_transform['en']),\n",
    "                 text_to_indices(tgt, 'cn', vocab_transform['cn'])) for src, tgt in filtered_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0639a1fc-b8de-48b4-8a47-bb1c82b9a964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11665"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b581b79-7aad-4880-9e67-9f347a28dcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([4, 140, 23, 279, 12, 32, 6, 686, 8, 6, 2043], [4, 1140, 4, 12, 4, 6, 4, 1470, 4, 9, 4, 6, 4, 1154, 5, 4, 1061, 4, 6, 4, 1148, 4, 6, 4, 4432, 4, 6827, 4, 2127, 4, 108])\n",
      "([4, 140, 19, 174, 115, 879, 5, 111, 28, 174, 879, 6, 9192, 147, 54, 10736, 992, 5, 66, 2335, 77, 9, 3113, 8, 1799, 19, 348, 166, 30, 4135, 5, 475, 627, 432, 19, 501, 13, 6, 1777, 8, 6, 1446, 5, 68, 296, 36, 41, 177, 10051], [4, 411, 4, 40, 4, 65, 4, 66, 4, 1322, 4, 3421, 4, 3236, 5, 8])\n",
      "([4, 27, 102, 10, 6, 1840, 10, 6689, 50, 9, 6571, 3360, 8, 5460], [4, 10, 4, 110, 4, 306, 4, 12, 4, 965, 4, 6, 4, 1389, 4, 33, 4, 626, 4, 1181])\n"
     ]
    }
   ],
   "source": [
    "random_index = [155,963,116]\n",
    "for random_data in random_index:\n",
    "    print(indexed_data[random_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cd04de9-7c2c-4061-a244-9bb01c777c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11665,\n",
       " 730,\n",
       " [([17, 3655, 3859, 8], [1193, 22, 890, 4867]),\n",
       "  ([2948, 3005], [1193, 22, 890]),\n",
       "  ([92, 6984, 110], [143, 8098, 22, 8108, 187])])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# 定义一个collate函数来处理填充\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    \n",
    "    # 使用clone().detach()来避免警告\n",
    "    src_batch = pad_sequence([seq.clone().detach() for seq in src_batch], padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence([seq.clone().detach() for seq in tgt_batch], padding_value=PAD_IDX)\n",
    "    \n",
    "    # 创建掩码\n",
    "    src_mask = (src_batch != PAD_IDX).unsqueeze(1)\n",
    "    tgt_mask = (tgt_batch != PAD_IDX).unsqueeze(1)\n",
    "    \n",
    "    # 确保目标序列的掩码形状与源序列一致\n",
    "    tgt_mask = tgt_mask[:, :-1, :-1]  # 这里我们去掉最后一个<eos>标记及其对应的掩码\n",
    "    \n",
    "    return src_batch, tgt_batch, src_mask, tgt_mask\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_dataset = TranslationDataset(indexed_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "len(train_dataset),len(train_dataloader),train_dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e37b1ce-3527-4247-af31-b48cc9975f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "\n",
    "# 初始化嵌入层\n",
    "d_model = 512  # 模型维度\n",
    "src_embed = Embeddings(d_model, len(vocab_transform['en']))\n",
    "tgt_embed = Embeddings(d_model, len(vocab_transform['cn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a9587-ff2e-42f1-a14f-acd311f67f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sentence embedding shape: torch.Size([5000, 6, 512])\n",
      "Target sentence embedding shape: torch.Size([5000, 6, 512])\n",
      "Source sentence embedding shape: torch.Size([5000, 4, 512])\n",
      "Target sentence embedding shape: torch.Size([5000, 5, 512])\n",
      "Source sentence embedding shape: torch.Size([5000, 5, 512])\n",
      "Target sentence embedding shape: torch.Size([5000, 7, 512])\n",
      "Source sentence embedding shape: torch.Size([5000, 3, 512])\n",
      "Target sentence embedding shape: torch.Size([5000, 3, 512])\n",
      "Source sentence embedding shape: torch.Size([5000, 4, 512])\n",
      "Target sentence embedding shape: torch.Size([5000, 3, 512])\n",
      "Source sentence embedding shape: torch.Size([5000, 4, 512])\n",
      "Target sentence embedding shape: torch.Size([5000, 5, 512])\n",
      "Source sentence embedding shape: torch.Size([5000, 6, 512])\n",
      "Target sentence embedding shape: torch.Size([5000, 5, 512])\n",
      "Source sentence embedding shape: torch.Size([5000, 6, 512])\n",
      "Target sentence embedding shape: torch.Size([5000, 5, 512])\n",
      "Source sentence embedding shape: torch.Size([5000, 6, 512])\n",
      "Target sentence embedding shape: torch.Size([5000, 3, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "\n",
    "# Assuming vocab_transform, token_transform, src_embed, tgt_embed, and data are already defined\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
    "\n",
    "d_model = 512  # Or whatever dimension you're using for your model\n",
    "pos_encoding = PositionalEncoding(d_model)\n",
    "\n",
    "# Define special token indices\n",
    "SOS_IDX = vocab_transform['en']['<sos>']\n",
    "EOS_IDX = vocab_transform['en']['<eos>']\n",
    "UNK_IDX = vocab_transform['en']['<unk>']\n",
    "\n",
    "# Convert text to indices\n",
    "def text_to_indices(text, lang, vocab):\n",
    "    indices = [vocab[token] if token in vocab else UNK_IDX for token in token_transform[lang](text)]\n",
    "    return torch.LongTensor([SOS_IDX] + indices + [EOS_IDX])\n",
    "\n",
    "# Process data into indexed tensors, ensuring only pairs are used\n",
    "indexed_data = []\n",
    "for row in data:\n",
    "    if len(row) >= 2:\n",
    "        src, tgt = row[:2]  # Take only the first two elements\n",
    "        indexed_data.append((text_to_indices(src, 'en', vocab_transform['en']),\n",
    "                             text_to_indices(tgt, 'cn', vocab_transform['cn'])))\n",
    "    # Optionally, you can log or handle rows with less than 2 elements\n",
    "\n",
    "# Process data and add positional encoding\n",
    "cnt = 0\n",
    "for src_indices, tgt_indices in indexed_data:\n",
    "    src_tensor = src_indices.unsqueeze(0)  # Add batch dimension\n",
    "    tgt_tensor = tgt_indices.unsqueeze(0)\n",
    "    \n",
    "    # Get embeddings\n",
    "    src_embedded = src_embed(src_tensor)\n",
    "    tgt_embedded = tgt_embed(tgt_tensor)\n",
    "    \n",
    "    # Add positional encoding\n",
    "    src_embedded_with_pos = pos_encoding(src_embedded)\n",
    "    tgt_embedded_with_pos = pos_encoding(tgt_embedded)\n",
    "    \n",
    "    cnt += 1\n",
    "    if cnt < 10:\n",
    "        print(f\"Source sentence embedding shape: {src_embedded_with_pos.shape}\")\n",
    "        print(f\"Target sentence embedding shape: {tgt_embedded_with_pos.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240de039-ab41-4974-844c-7847a65cb67d",
   "metadata": {},
   "source": [
    "## 示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379acdc4-ef95-409a-b88b-a5bcfe5d5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印词汇表大小\n",
    "print(f\"English vocabulary size: {len(en_word_to_idx)}\")\n",
    "print(f\"Chinese vocabulary size: {len(cn_word_to_idx)}\")\n",
    "\n",
    "# 定义模型参数\n",
    "d_model = 512  # 模型维度\n",
    "max_len = 1000  # 假设最大序列长度是1000\n",
    "\n",
    "# 初始化嵌入层和位置编码层\n",
    "src_embedding = Embeddings(d_model, len(en_word_to_idx))\n",
    "tgt_embedding = Embeddings(d_model, len(cn_word_to_idx))\n",
    "pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "# 示例：将一个句子转换为嵌入向量\n",
    "# 假设我们有一句话\"Hello, how are you?\"\n",
    "src_sentence = \"Hello, how are you?\"\n",
    "tgt_sentence = \"你好，你好吗？\"\n",
    "\n",
    "# 将句子转换为索引\n",
    "src_indices = [en_word_to_idx.get(token, en_word_to_idx['<unk>']) for token in token_transform['en'](src_sentence)]\n",
    "tgt_indices = [cn_word_to_idx.get(token, cn_word_to_idx['<unk>']) for token in token_transform['cn'](tgt_sentence)]\n",
    "\n",
    "# 转换为张量\n",
    "src_tensor = torch.LongTensor(src_indices).unsqueeze(0)  # 添加批次维度\n",
    "tgt_tensor = torch.LongTensor(tgt_indices).unsqueeze(0)\n",
    "\n",
    "# 获取嵌入并添加位置编码\n",
    "src_embedded = pos_encoding(src_embedding(src_tensor))\n",
    "tgt_embedded = pos_encoding(tgt_embedding(tgt_tensor))\n",
    "\n",
    "print(\"Source sentence embedding shape:\", src_embedded.shape)\n",
    "print(\"Target sentence embedding shape:\", tgt_embedded.shape)\n",
    "\n",
    "# 假设你要使用这些嵌入向量进行进一步的处理，例如传递给Transformer模型的编码器或解码器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15754b23-41dc-4058-b046-95bd406d02b6",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f7a4b85-85db-4e27-8165-daa7ab0f295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None):\n",
    "    d_k = query.size(-1)\n",
    "\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "                             for l, x in zip(self.linears, (query, key, value))]\n",
    "        x, self.attn = attention(query, key, value, mask=mask)\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "\n",
    "        return self.a_2 * (x - mean) / torch.sqrt(std ** 2 + self.eps) + self.b_2\n",
    "\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + sublayer(self.norm(x))\n",
    "\n",
    "\n",
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(F.relu(self.w_1(x)))\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, feed_forward):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size), 3)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        m = memory\n",
    "\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)\n",
    "\n",
    "\n",
    "def init_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8):\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff)\n",
    "    position = PositionalEncoding(d_model)\n",
    "    return Transformer(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff)), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff)), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b83f8234-562a-410f-b5f6-3b72218a55e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model(len(vocab_transform['en']), len(vocab_transform['cn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c54f503-ad9e-4759-b365-ab5e290a3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)  # 忽略填充标记\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0b924be-7a3a-4755-b201-8b9c0417904f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6866/4186518942.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  src_batch = pad_sequence([torch.tensor(seq) for seq in src_batch], padding_value=PAD_IDX)\n",
      "/tmp/ipykernel_6866/4186518942.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tgt_batch = pad_sequence([torch.tensor(seq) for seq in tgt_batch], padding_value=PAD_IDX)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (660) must match the size of tensor b (661) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m memory \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(src, src_mask)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 解码\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 生成\u001b[39;00m\n\u001b[1;32m     20\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerator(output)\n",
      "Cell \u001b[0;32mIn[25], line 137\u001b[0m, in \u001b[0;36mTransformer.decode\u001b[0;34m(self, memory, src_mask, tgt, tgt_mask)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, memory, src_mask, tgt, tgt_mask):\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgt_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[25], line 103\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, memory, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, memory, src_mask, tgt_mask):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 103\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[25], line 119\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[0;34m(self, x, memory, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, memory, src_mask, tgt_mask):\n\u001b[1;32m    117\u001b[0m     m \u001b[38;5;241m=\u001b[39m memory\n\u001b[0;32m--> 119\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msublayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublayer[\u001b[38;5;241m1\u001b[39m](x, \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_attn(x, m, m, src_mask))\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublayer[\u001b[38;5;241m2\u001b[39m](x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[25], line 53\u001b[0m, in \u001b[0;36mSublayerConnection.forward\u001b[0;34m(self, x, sublayer)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, sublayer):\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[43msublayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 119\u001b[0m, in \u001b[0;36mDecoderLayer.forward.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, memory, src_mask, tgt_mask):\n\u001b[1;32m    117\u001b[0m     m \u001b[38;5;241m=\u001b[39m memory\n\u001b[0;32m--> 119\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublayer[\u001b[38;5;241m0\u001b[39m](x, \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    120\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublayer[\u001b[38;5;241m1\u001b[39m](x, \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_attn(x, m, m, src_mask))\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublayer[\u001b[38;5;241m2\u001b[39m](x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[25], line 28\u001b[0m, in \u001b[0;36mMultiHeadedAttention.forward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m nbatches \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     26\u001b[0m query, key, value \u001b[38;5;241m=\u001b[39m [l(x)\u001b[38;5;241m.\u001b[39mview(nbatches, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     27\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m l, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinears, (query, key, value))]\n\u001b[0;32m---> 28\u001b[0m x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn \u001b[38;5;241m=\u001b[39m \u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(nbatches, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinears[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](x)\n",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m, in \u001b[0;36mattention\u001b[0;34m(query, key, value, mask)\u001b[0m\n\u001b[1;32m      4\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(query, key\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(d_k)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1e9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m p_attn \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmatmul(p_attn, value), p_attn\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (660) must match the size of tensor b (661) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 1  # 或任何你认为合适的训练轮数\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt, src_mask, tgt_mask in train_dataloader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        src_mask, tgt_mask = src_mask.to(device), tgt_mask.to(device)\n",
    "        \n",
    "        # 编码\n",
    "        memory = model.encode(src, src_mask)\n",
    "        \n",
    "        # 解码\n",
    "        output = model.decode(memory, src_mask, tgt[:, :-1], tgt_mask[:, :-1, :-1])\n",
    "        \n",
    "        # 生成\n",
    "        output = model.generator(output)\n",
    "        \n",
    "        # 计算损失\n",
    "        # 目标序列去掉第一个<sos>标记\n",
    "        loss = criterion(output.view(-1, output.size(-1)), tgt[:, 1:].contiguous().view(-1))\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(data_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd58f981-771b-41b8-8b76-cc6efe631d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
